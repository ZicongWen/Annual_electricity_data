{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from datetime import date\n",
    "import datetime\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import re\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df: pd.DataFrame, path, name, index = False):\n",
    "    \"\"\"\n",
    "    Saving dataframe to csv file\n",
    "    df: dataframe\n",
    "    path: destination path\n",
    "    name: name of the file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    if path[-1] == '/':\n",
    "        df.to_csv(path+name, index = index)\n",
    "    else:\n",
    "        df.to_csv(path + '/' + name, index = index)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, path: str = None, headers = {'content-type': 'application/json', 'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:22.0) Gecko/20100101 Firefox/22.0'}):\n",
    "    \"\"\"\n",
    "    Dowloading files from the give URL using requests module, with specified header and store to desire path if provided. \n",
    "    Otherwises, store to the default path that is under the current directory called with region specified\n",
    "    url: url to download files\n",
    "    path: path to store files\n",
    "    headers: headers that use for the request.get()\n",
    "    \"\"\"\n",
    "    \n",
    "    response2 = requests.get(url, headers=headers)\n",
    "    # print(response2.status_code)\n",
    "    if response2.status_code != 200:\n",
    "        raise Exception(f'Code error, {response2.status_code}')\n",
    "    df = pd.read_csv(io.StringIO(response2.text))\n",
    "    \n",
    "    last_bash = url.rfind('/')\n",
    "    name =  url[last_bash + 1 :]\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    try:\n",
    "        save_to_csv(df, path, name)\n",
    "    except:\n",
    "        print('出错了')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hour_interval(src:str, dst:str, name:str):\n",
    "    \"\"\"\n",
    "    Using the combined csv to reduce to 1 hour interval\n",
    "    src: source\n",
    "    dst: Destination\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(src)\n",
    "    df['SETTLEMENTDATE'] =  pd.to_datetime(df['SETTLEMENTDATE'])\n",
    "    df = df.set_index(df['SETTLEMENTDATE'])\n",
    "    new_df = df.groupby(pd.Grouper(freq='60min')).mean()\n",
    "    save_to_csv(new_df, dst, name, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_files(path = '', name = '*', end = '.csv') -> list:\n",
    "    if path[-1] != '/':\n",
    "        path += '/'\n",
    "    result = []\n",
    "    result += glob.glob(path + name + end)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv(src:list, dst, name):\n",
    "    \"\"\"\n",
    "    Combine .csv files to the specific dir with name total_REG.csv\n",
    "    Three different .csv files are generated, original file, dropped negative number file and nagative to zero file\n",
    "    src: source path\n",
    "    dst: destination path\n",
    "    name: name\n",
    "    \"\"\"\n",
    "    \n",
    "    # src = src[:-1]\n",
    "    all_files = []\n",
    "    for i in range(len(src)):\n",
    "        all_files.extend(find_all_files(path = src[i] , name = '*'))\n",
    "    li = []\n",
    "    \n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "\n",
    "    frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "    frame2 = frame.loc[frame['RRP'] > 0]\n",
    "    frame3 = frame.copy()\n",
    "    frame3.loc[(frame3.RRP < 0),'RRP']= 0\n",
    "\n",
    "    if dst[-1] != '/':\n",
    "         dst += '/'\n",
    "\n",
    "    if not os.path.exists(dst):\n",
    "        os.makedirs(dst)\n",
    "        \n",
    "    name1 = 'total.csv'\n",
    "    name2 = 'total_reduced.csv'\n",
    "    name3 = 'total_toZero.csv'\n",
    "    save_to_csv(frame, dst, name1)\n",
    "    save_to_csv(frame2, dst, name2)\n",
    "    save_to_csv(frame3, dst, name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exist(path):\n",
    "    \"\"\"\n",
    "    check if path exists, True if exists else False\n",
    "    path: desire path\n",
    "    \"\"\"\n",
    "    if path[-1] != '/':\n",
    "        path += '/'\n",
    "    return os.path.exists(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdirs(rootdir):\n",
    "    paths = []\n",
    "    for file in os.listdir(rootdir):\n",
    "        d = os.path.join(rootdir, file)\n",
    "        if os.path.isdir(d):\n",
    "            paths.append(d)\n",
    "            listdirs(d)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(year:list = ['22', '21', '19', '18', '17'], reg:list = ['SA', 'QLD', 'VIC', 'TAS', 'NSW'], csv_names:list = ['total_reduced.csv', 'total_toZero.csv', 'total.csv'], path:str = '', amount_path:str = 'Splited.csv'):\n",
    "    \"\"\"\n",
    "    plotting data\n",
    "\n",
    "    reg: regions\n",
    "    csv_names: name of the csv names\n",
    "    path: path to save the graph\n",
    "    amount_path: path to the amount csv data\n",
    "    \"\"\"\n",
    "    amount = pd.read_csv(amount_path)\n",
    "    Total_year_dirs = listdirs('Total_year_one_hour')\n",
    "    if path != '':\n",
    "        path += '/'\n",
    "    for dir in Total_year_dirs:\n",
    "        for j in year:\n",
    "            if j in dir:\n",
    "                for k in reg:\n",
    "                    if k in dir:\n",
    "                        for i in csv_names:\n",
    "                            plot_yearly_graph(dir+'/'+i, amount, path + 'Graphs/' + i[:-4] + dir[dir.find('/'):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_wd(path:str):\n",
    "    if path[-1] != '/':\n",
    "        path += '/'\n",
    "    shutil.rmtree(path)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(x1:list, x_name:list, y_name:str, title:str, path:str, width = 0.95):\n",
    "    \"\"\"\n",
    "    Plot the bar graph with the given data and parameters\n",
    "\n",
    "    x1: data\n",
    "    x_name: name of the x-axis\n",
    "    y_name: name of the y-axis\n",
    "    title\n",
    "    path: path where to store the graph\n",
    "    width: width of the bar, deault value is 0.95\n",
    "    \"\"\"\n",
    "    if not check_exist(path):\n",
    "        os.makedirs(path)\n",
    "    if path[-1] != '/':\n",
    "        path += '/'\n",
    "    ind = np.arange(len(x1))  # the x locations for the groups\n",
    "    width = width       # the width of the bars\n",
    "    fig = plt.figure()\n",
    "\n",
    "    fig.set_figwidth(80)\n",
    "    fig.set_figheight(50)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    colormat=np.where(x1>0, 'b','r')\n",
    "    rects1 = ax.bar(ind, x1, width, color=colormat, edgecolor = 'white')\n",
    "    # rects2 = ax.bar(ind+width, x2, width, color='seagreen')\n",
    "\n",
    "    # add some\n",
    "    ax.set_ylabel(y_name, fontsize = 40)\n",
    "    ax.set_title(title, fontsize = 40)\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(x_name, fontsize = 40)\n",
    "    plt.xticks(rotation=90)\n",
    "    xlocs, xlabs = plt.xticks()\n",
    "    for i, v in enumerate(x1): \n",
    "        if v > 0:\n",
    "            plt.text(xlocs[i] - 1, v + 50, str(round(v, 2)), fontsize = 30)\n",
    "        else:\n",
    "            plt.text(xlocs[i] - 1, 0 , str(round(v, 2)), fontsize = 30)\n",
    "    # plt.show()\n",
    "    plt.savefig(path + title + '.jpg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annuel_report(price:pd.DataFrame, amount:pd.DataFrame, name:str):\n",
    "    print('ann: ', 'Graphs/Annuel Summary/' + name[name.find('/')+ 1:name.rfind('/')+ 1 ])\n",
    "    # name = name[name.rfind('/') + 1 :]\n",
    "    index = 0\n",
    "    df = pd.DataFrame()\n",
    "    df_index = []\n",
    "    while index + 24 <= len(price):\n",
    "        data = price.iloc[index:index + 24, 2] * amount.iloc[index:index + 24, 1]\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        df = pd.concat([df, data], axis = 1)\n",
    "        index += 24\n",
    "        df_index.append(price.iloc[index, 0][:10])\n",
    "    df = df.set_axis(df_index, axis=1, inplace=False)\n",
    "    df['Avg'] = df.mean(axis = 1)\n",
    "    \n",
    "\n",
    "    save_to_csv(df, 'Graphs/Annuel Summary/'+name[name.find('/')+ 1:name.rfind('/')+ 1] , name[name.rfind('/') + 1:]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_yearly_graph(total_year_chart:str, amount:pd.DataFrame, save_path:str):\n",
    "    \"\"\"\n",
    "    Plot the data yearly. Automatically detect if the data has been calculated and plotted\n",
    "    \n",
    "    total_year_chart: path that point to the prices csv\n",
    "    amount: simulation of the electricity that is generated by the solar system\n",
    "    save_path: path that stores the the graph\n",
    "    \"\"\"\n",
    "    price = pd.read_csv(total_year_chart)\n",
    "    \n",
    "    curruent_day = -1\n",
    "    if check_exist(save_path):\n",
    "        if '.DS_Store' in os.listdir(save_path):\n",
    "            curruent_day = (len(os.listdir(save_path)) - 1) * 24\n",
    "        else:\n",
    "            curruent_day = len(os.listdir(save_path)) * 24\n",
    "    if curruent_day > 0:\n",
    "        index = curruent_day\n",
    "    elif curruent_day == (len(price)-1)/24:\n",
    "        return \n",
    "    else:\n",
    "        index = 0\n",
    "\n",
    "    annuel_report(price, amount, save_path)\n",
    "    \n",
    "    while index + 24 <= len(price):\n",
    "        os.system('clear')\n",
    "        if check_exist(save_path + '/Day ' + str((index+24)/24) + '.jpg'):\n",
    "            index += 24\n",
    "        else:\n",
    "            x_axis = price.iloc[index:index + 24, 0]\n",
    "            data = price.iloc[index:index + 24, 2] * amount.iloc[index:index + 24, 1]\n",
    "            print(str(datetime.datetime.strptime(price.iloc[index - 1, 0], '%Y-%m-%d %H:%M:%S').date()))\n",
    "            bar_plot(data, x_axis, 'Earning', str(datetime.datetime.strptime(price.iloc[index - 1, 0], '%Y-%m-%d %H:%M:%S').date()), save_path)\n",
    "            index += 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    urls, paths = {'SA1': [], 'QLD1' : [], 'VIC1':[], 'TAS1':[], 'NSW1':[]}, {'SA1': [], 'QLD1' : [], 'VIC1':[], 'TAS1':[], 'NSW1':[]}\n",
    "    regions = ['NSW1', 'SA1', 'VIC1', 'QLD1', 'TAS1']\n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "\n",
    "    for state in regions:\n",
    "        for j in range(int(str(date.today().year)[-2:]), int(str(date.today().year)[-2:]) - 6, -1):\n",
    "            if int(str(date.today().year)[-2:]) == j:\n",
    "                for i in range(1, int(date.today().month)):\n",
    "                    if i < 10:\n",
    "                        url = 'https://aemo.com.au/aemo/data/nem/priceanddemand/PRICE_AND_DEMAND_20' + str(j) + '0' + str(i) + '_' + state + '.csv'\n",
    "                    else:\n",
    "                        url = 'https://aemo.com.au/aemo/data/nem/priceanddemand/PRICE_AND_DEMAND_20' + str(j) + str(i) + '_' + state + '.csv'\n",
    "                    \n",
    "                    bucket = []\n",
    "                    bucket.append(url)\n",
    "                    bucket.append([state[:-1], str(j)])\n",
    "                    urls[state].append(bucket)  \n",
    "            else:\n",
    "                for i in range(1,13):\n",
    "                    if i < 10:\n",
    "                        url = 'https://aemo.com.au/aemo/data/nem/priceanddemand/PRICE_AND_DEMAND_20' + str(j) + '0' + str(i) + '_' + state + '.csv'\n",
    "                    else:\n",
    "                        url = 'https://aemo.com.au/aemo/data/nem/priceanddemand/PRICE_AND_DEMAND_20' + str(j) + str(i) + '_' + state + '.csv'\n",
    "                    \n",
    "                    bucket = []\n",
    "                    bucket.append(url)\n",
    "                    bucket.append([state[:-1], str(j)])\n",
    "                    urls[state].append(bucket)\n",
    "\n",
    "    # for i in regions:\n",
    "    #     if check_exist(i):\n",
    "    #         raise Exception(f'The path exists, please delete it follow this dir: {os.getcwd()}' + '/' + f'{i}')\n",
    "\n",
    "    flag = bool()\n",
    "    for reg in regions:\n",
    "        print(reg)\n",
    "        flag = check_exist(reg[:-1])\n",
    "        if flag:\n",
    "            break\n",
    "    # print(flag)\n",
    "    if flag:\n",
    "        con = input('some data has already existed, [Y] for cover the previous data, [N] use the current data.')\n",
    "        if con.lower() == 'y':\n",
    "            for reg in regions:\n",
    "                if check_exist(reg):\n",
    "                    delete_wd(reg)\n",
    "            \n",
    "            # delete_wd('Total/')\n",
    "\n",
    "            for reg in regions:\n",
    "                for i in urls[reg]:\n",
    "                    temp = download(i[0], '/'.join(i[1]))\n",
    "                    if temp not in paths[reg]:\n",
    "                        paths[reg].append(temp)\n",
    "                \n",
    "                # combine_csv(paths[reg], 'Total/', reg[:-1])\n",
    "        else:\n",
    "            if os.getcwd()+'/Total' in listdirs(os.getcwd()):\n",
    "                con2 = input('The combined CSV is found, do you want to delete them and create new csv? [Y]es [N]o')\n",
    "                if con2.lower() == 'y':\n",
    "                    delete_wd('Total/')\n",
    "            for reg in regions:\n",
    "                paths[reg].extend(listdirs(reg[:-1]))\n",
    "                \n",
    "    else:\n",
    "        for reg in regions:\n",
    "                for i in urls[reg]:\n",
    "                    temp = download(i[0], '/'.join(i[1]))\n",
    "                    if temp not in paths[reg]:\n",
    "                        paths[reg].append(temp)\n",
    "                \n",
    "                # combine_csv(paths[reg], 'Total/', reg[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if not check_exist('Total_year'):\n",
    "        for i in paths.values():\n",
    "            for j in i:\n",
    "                combine_csv([j], 'Total_year/'+str(j.replace('/', '-')), j.replace('/','_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Reduce to 1 hour interval\n",
    "    if not check_exist(\"Total_year_one_hour\"):\n",
    "        before_ave_files = []\n",
    "        Total_year_dirs = listdirs('Total_year')\n",
    "        for i in Total_year_dirs:\n",
    "            before_ave_files.extend(find_all_files(path = i))\n",
    "        for i in before_ave_files:\n",
    "            one_hour_interval(i, 'Total_year_one_hour' + i[i.find('/') : i.rfind('/')], i[i.rfind('/'):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J2020-12-21\n",
      "\u001b[H\u001b[2J2020-12-22\n",
      "\u001b[H\u001b[2J2020-12-23\n",
      "\u001b[H\u001b[2J2020-12-24\n",
      "\u001b[H\u001b[2J2020-12-25\n",
      "\u001b[H\u001b[2J2020-12-26\n",
      "\u001b[H\u001b[2J2020-12-27\n",
      "\u001b[H\u001b[2J2020-12-28\n",
      "\u001b[H\u001b[2J2020-12-29\n",
      "\u001b[H\u001b[2J2020-12-30\n"
     ]
    }
   ],
   "source": [
    "    desire_reg = input('地区(SA, QLD, TAS, VIC, NSW)，无输入为处理全部: ').upper()\n",
    "    type_file = input('模式(total_reduced.csv, total_toZero.csv, total.csv), 无输入为处理全部：')\n",
    "    amount_path = input('模拟发电量的地址, 无输入为处理全部：')\n",
    "    path = input('储存地址，无输入为储存在程序所在地址: ')\n",
    "    year = input('年份（只输入最后两位数），无输入为处理全部：')\n",
    "    year = re.split(' |, |,', year)\n",
    "    if amount_path == '':\n",
    "        plot_data(year, re.split(' |, |,', desire_reg), re.split(' |, |,', type_file), path)\n",
    "    else:\n",
    "        plot_data(year, re.split(' |, |,', desire_reg), re.split(' |, |,', type_file), path, amount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76ea754b25b726a93d8de7d3b8af90723f92451c0edd4df20eb3049105300d87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
